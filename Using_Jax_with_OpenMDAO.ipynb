{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ol-jicl6una",
    "outputId": "d7c564fd-bd76-4dd3-dfaa-94a00f9b2275"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting git+https://github.com/robfalck/OpenMDAO.git@math_subpackage\n",
      "  Cloning https://github.com/robfalck/OpenMDAO.git (to revision math_subpackage) to /tmp/pip-req-build-s4ab1ldm\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/robfalck/OpenMDAO.git /tmp/pip-req-build-s4ab1ldm\n",
      "  Running command git checkout -b math_subpackage --track origin/math_subpackage\n",
      "  Switched to a new branch 'math_subpackage'\n",
      "  Branch 'math_subpackage' set up to track remote branch 'math_subpackage' from 'origin'.\n",
      "  Resolved https://github.com/robfalck/OpenMDAO.git to commit 1ac504fcd3aa42881137eba3046a6cd2cb66646b\n",
      "  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.10/dist-packages (from openmdao==3.26.1.dev0) (3.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openmdao==3.26.1.dev0) (1.22.4)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from openmdao==3.26.1.dev0) (1.10.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from openmdao==3.26.1.dev0) (2.27.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from openmdao==3.26.1.dev0) (23.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->openmdao==3.26.1.dev0) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->openmdao==3.26.1.dev0) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->openmdao==3.26.1.dev0) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->openmdao==3.26.1.dev0) (3.4)\n",
      "Building wheels for collected packages: openmdao\n",
      "  Building wheel for openmdao (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for openmdao: filename=openmdao-3.26.1.dev0-py3-none-any.whl size=6126713 sha256=cdaf0e4513cb8b52893899a312bbc22172964ef53b4595e2e26ee3163f985207\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-yi_3avpj/wheels/83/59/30/bf888efb14694b0dac57ae7b531996f98d9bfe812b69b6ef67\n",
      "Successfully built openmdao\n",
      "Installing collected packages: openmdao\n",
      "Successfully installed openmdao-3.26.1.dev0\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install git+https://github.com/robfalck/OpenMDAO.git@math_subpackage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def act_tanh(x, mu=1.0E-2, z=0., a=-1., b=1.):\n",
    "    \"\"\"\n",
    "    Differentiable activation function based on the hyperbolic tangent.\n",
    "\n",
    "    act_tanh can be used to approximate a step function from `a` to `b`, occurring at x=z.\n",
    "    Smaller values of parameter `mu` more accurately represent a step function but the \"sharpness\" of the corners in the\n",
    "    response may be more difficult for gradient-based approaches to resolve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : float or jnp.array\n",
    "        The input at which the value of the activation function\n",
    "        is to be computed.\n",
    "    mu : float\n",
    "        A shaping parameter which impacts the \"abruptness\" of\n",
    "        the activation function. As this value approaches zero\n",
    "        the response approaches that of a step function.\n",
    "    z : float\n",
    "        The value of the independent variable about which the\n",
    "        activation response is centered.\n",
    "    a : float\n",
    "        The initial value that the input asymptotically approaches\n",
    "        as x approaches negative infinity.\n",
    "    b : float\n",
    "        The final value that the input asymptotically approaches\n",
    "        as x approaches positive infinity.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float or jnp.array\n",
    "        The value of the activation response at the given input.\n",
    "    \"\"\"\n",
    "    dy = b - a\n",
    "    tanh_term = jnp.tanh((x - z) / mu)\n",
    "    return 0.5 * dy * (1 + tanh_term) + a\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from functools import partial\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import openmdao.api as om\n",
    "# from openmdao.math import act_tanh\n",
    "\n",
    "\n",
    "class CountingComp(om.ExplicitComponent):\n",
    "    \n",
    "    def initialize(self):\n",
    "        self.options.declare('vec_size', types=(int,))\n",
    "        self.options.declare('threshold', types=(float,), default=0.0)\n",
    "        self.options.declare('mu', types=(float,), default=0.01)\n",
    "    \n",
    "    def setup(self):\n",
    "        n = self.options['vec_size']\n",
    "        self.add_input('x', shape=(n,))\n",
    "        self.add_output('count', shape=(1,))\n",
    "        \n",
    "        # The partials are a dense row in this case (1 row x N inputs)\n",
    "        # There is no need to specify a sparsity pattern.\n",
    "        self.declare_partials(of='count', wrt='x')\n",
    "\n",
    "    @partial(jax.jit, static_argnums=(0,))\n",
    "    def _compute_partials_jacfwd(self, x):\n",
    "        deriv_func = jax.jacfwd(self.compute_primal, argnums=[0])\n",
    "        dx, = deriv_func(x)\n",
    "        return dx\n",
    "    \n",
    "    @partial(jax.jit, static_argnums=(0,))\n",
    "    def _compute_partials_jacrev(self, x):\n",
    "        deriv_func = jax.jacrev(self.compute_primal, argnums=[0])\n",
    "        # Always returns a tuple\n",
    "        dx, = deriv_func(x)\n",
    "        return dx\n",
    "\n",
    "    @partial(jax.jit, static_argnums=(0,))\n",
    "    def _compute_partials_jvp(self, x):\n",
    "        # Note that JVP is a poor choice here, since the jacobian is a row vector!\n",
    "        # We have to call it once with each individual element in x set to 1.0\n",
    "        # while all the others are zero in order to get a correct result!\n",
    "        \n",
    "        # jvp always returns the primal and the jvp\n",
    "        # This will give incorrect results! There is \"cross-talk\" amongs the different\n",
    "        # indices in the tangents.\n",
    "        _, dx = jax.jvp(self.compute_primal,\n",
    "                        primals=(x,),\n",
    "                        tangents=(jnp.ones_like(x),))\n",
    "        return dx\n",
    "\n",
    "    # TODO: how to properly use vjp?\n",
    "    @partial(jax.jit, static_argnums=(0,))\n",
    "    def _compute_partials_vjp(self, x):\n",
    "        # Note that JVP is a poor choice here, since the jacobian is a row vector!\n",
    "        # We have to call it once with each individual element in x set to 1.0\n",
    "        # while all the others are zero in order to get a correct result!\n",
    "        \n",
    "        # vjp always returns the primal and the vjp\n",
    "        _, vjp_fun = jax.vjp(self.compute_primal, x)\n",
    "        dx = vjp_fun(self.compute_primal(x))\n",
    "        return dx\n",
    " \n",
    "    # TODO: how to use jax.jit and get self.<attribute> into the function here? Wrapped function?\n",
    "    @partial(jax.jit, static_argnums=(0,))\n",
    "    def compute_primal(self, x):\n",
    "        mu = self.options['mu']\n",
    "        z = self.options['threshold']\n",
    "        return jnp.sum(act_tanh(x, mu, z, 0.0, 1.0))\n",
    "    \n",
    "    def compute(self, inputs, outputs):\n",
    "        z = self.options['threshold']\n",
    "        x = inputs['x']\n",
    "        mu = self.options['mu']\n",
    "        \n",
    "        outputs['count'] = self.compute_primal(*inputs.values())\n",
    "        \n",
    "    def compute_partials(self, inputs, partials):\n",
    "        dx = self._compute_partials_jvp(*inputs.values())\n",
    "\n",
    "        partials['count', 'x'] = dx\n",
    "\n",
    "    def _tree_flatten(self):\n",
    "        children = tuple()  # arrays / dynamic values\n",
    "        aux_data = {'options': self.options}  # static values\n",
    "        return (children, aux_data)\n",
    "\n",
    "    @classmethod\n",
    "    def _tree_unflatten(cls, aux_data, children):\n",
    "        return cls(*children, **aux_data)\n",
    "\n",
    "from jax import tree_util\n",
    "tree_util.register_pytree_node(CountingComp,\n",
    "                               CountingComp._tree_flatten,\n",
    "                               CountingComp._tree_unflatten)\n"
   ],
   "metadata": {
    "id": "Lu5axaaE7hbV"
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "N = 10\n",
    "\n",
    "p = om.Problem()\n",
    "p.model.add_subsystem('counter',\n",
    "                      CountingComp(vec_size=N,threshold=0.5, mu=0.01),\n",
    "                      promotes_inputs=['x'], promotes_outputs=['count'])\n",
    "p.setup(force_alloc_complex=True)\n",
    "p.set_val('x', np.linspace(0, 1, N))\n",
    "p.run_model()\n",
    "p.model.list_inputs(print_arrays=True)\n",
    "p.model.list_outputs(print_arrays=True)\n",
    "\n",
    "with np.printoptions(linewidth=1024):\n",
    "    p.check_partials(method='cs', compact_print=False);"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JvV4x9BP7tw9",
    "outputId": "f9cbe9f6-0017-4cd9-ca1a-bef8a2dea601"
   },
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Input(s) in 'model'\n",
      "\n",
      "varname  val                 \n",
      "-------  --------------------\n",
      "counter\n",
      "  x      |1.87577145|        \n",
      "         val:\n",
      "         array([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n",
      "                0.55555556, 0.66666667, 0.77777778, 0.88888889, 1.        ])\n",
      "\n",
      "\n",
      "1 Explicit Output(s) in 'model'\n",
      "\n",
      "varname  val \n",
      "-------  ----\n",
      "counter\n",
      "  count  [5.]\n",
      "\n",
      "\n",
      "0 Implicit Output(s) in 'model'\n",
      "\n",
      "\n",
      "---------------------------------\n",
      "Component: CountingComp 'counter'\n",
      "---------------------------------\n",
      "\n",
      "  counter: 'count' wrt 'x'\n",
      "    Analytic Magnitude: 1.890396e-02\n",
      "          Fd Magnitude: 4.227054e-03 (cs:None)\n",
      "    Absolute Error (Jan - Jfd) : 1.742859e-02 *\n",
      "\n",
      "    Relative Error (Jan - Jfd) / Jfd : 4.123106e+00 *\n",
      "\n",
      "    Raw Analytic Derivative (Jfor)\n",
      "[[0.00597796 0.00597796 0.00597796 0.00597796 0.00597796 0.00597796 0.00597796 0.00597796 0.00597796 0.00597796]]\n",
      "\n",
      "    Raw CS Derivative (Jcs)\n",
      "[[7.44015195e-42 3.33096671e-32 1.49127858e-22 6.67647559e-13 2.98897836e-03 2.98897836e-03 6.67647559e-13 1.49127858e-22 3.33096671e-32 7.44015195e-42]]\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "zwO8rUNQdyTy"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}